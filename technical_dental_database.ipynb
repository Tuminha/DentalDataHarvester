{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/sortedcontainers-2.4.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/pdfminer.six-20200121-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/grobid_client_python-0.0.7-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pdfminer.six==20221105\n",
      "  Using cached pdfminer.six-20221105-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from pdfminer.six==20221105) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from pdfminer.six==20221105) (41.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20221105) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105) (2.21)\n",
      "Using cached pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "Installing collected packages: pdfminer.six\n",
      "  Attempting uninstall: pdfminer.six\n",
      "    Found existing installation: pdfminer.six 20221105\n",
      "    Uninstalling pdfminer.six-20221105:\n",
      "      Successfully uninstalled pdfminer.six-20221105\n",
      "Successfully installed pdfminer.six-20221105\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six==20221105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/sortedcontainers-2.4.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/pdfminer.six-20200121-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/grobid_client_python-0.0.7-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/sortedcontainers-2.4.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/pdfminer.six-20200121-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages/grobid_client_python-0.0.7-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/datatrove.git\n",
      "  Cloning https://github.com/huggingface/datatrove.git to /private/var/folders/cd/2c6x3jgj47j_fwl7231ts7m00000gn/T/pip-req-build-krrhj7pj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datatrove.git /private/var/folders/cd/2c6x3jgj47j_fwl7231ts7m00000gn/T/pip-req-build-krrhj7pj\n",
      "  Resolved https://github.com/huggingface/datatrove.git to commit 6d06210c337b6b54dfc48bce44ac32316da84f86\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dill>=0.3.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (0.3.7)\n",
      "Requirement already satisfied: fsspec>=2023.12.2 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (0.22.2)\n",
      "Requirement already satisfied: humanize in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (4.9.0)\n",
      "Requirement already satisfied: loguru>=0.7.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (0.7.2)\n",
      "Requirement already satisfied: multiprocess in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (0.70.15)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (1.26.0)\n",
      "Requirement already satisfied: tqdm in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from datatrove==0.2.0) (4.66.1)\n",
      "Requirement already satisfied: filelock in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->datatrove==0.2.0) (3.12.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->datatrove==0.2.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->datatrove==0.2.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->datatrove==0.2.0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->datatrove==0.2.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->datatrove==0.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->datatrove==0.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->datatrove==0.2.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/franciscoteixeirabarbosa/anaconda3/envs/streamlitapp/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->datatrove==0.2.0) (2023.7.22)\n",
      "Building wheels for collected packages: datatrove\n",
      "  Building wheel for datatrove (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for datatrove: filename=datatrove-0.2.0-py3-none-any.whl size=16646697 sha256=886ec4c7bc2e005c29722a9b62a73b3307f52588c1fb5e71dd95949e72c2d9c3\n",
      "  Stored in directory: /private/var/folders/cd/2c6x3jgj47j_fwl7231ts7m00000gn/T/pip-ephem-wheel-cache-qvq3_sy3/wheels/d1/c4/e1/c220bd9ceccf54ae8dfb14fc550f9a92dc794a0b54a0470b45\n",
      "Successfully built datatrove\n",
      "Installing collected packages: datatrove\n",
      "  Attempting uninstall: datatrove\n",
      "    Found existing installation: datatrove 0.0.1\n",
      "    Uninstalling datatrove-0.0.1:\n",
      "      Successfully uninstalled datatrove-0.0.1\n",
      "Successfully installed datatrove-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/huggingface/datatrove.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: /Volumes/LaCie/technical_dental_database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 22:32:04.962 | INFO     | datatrove.utils.logging:add_task_logger:47 - Launching pipeline for rank=0\n",
      "2024-04-22 22:32:04.963 | INFO     | datatrove.utils.logging:log_pipeline:76 - \n",
      "--- 🛠️ PIPELINE 🛠\n",
      "📖 - READER: 📒 Parquet\n",
      "🔻 - FILTER: 👤 Lambda\n",
      "💽 - WRITER: 🐿 Jsonl\n",
      "2024-04-22 22:32:21.601 | INFO     | datatrove.pipeline.readers.base:read_files_shard:193 - Reading input file CC-MAIN-2013-20/000_00000.parquet\n",
      "2024-04-22 22:32:24.213 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 1/10 tasks completed.\n",
      "2024-04-22 22:32:24.788 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 2/10 tasks completed.\n",
      "2024-04-22 22:32:29.597 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 3/10 tasks completed.\n",
      "2024-04-22 22:32:35.421 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 4/10 tasks completed.\n",
      "2024-04-22 22:32:36.436 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 5/10 tasks completed.\n",
      "2024-04-22 22:32:37.454 | SUCCESS  | datatrove.executor.base:_run_for_rank:85 - Processing done for rank=0\n",
      "2024-04-22 22:32:37.460 | INFO     | datatrove.executor.base:_run_for_rank:91 - \n",
      "\n",
      "📉📉📉 Stats: Task 0 📉📉📉\n",
      "\n",
      "Total Runtime: 0 seconds\n",
      "\n",
      "📖 - READER: 📒 Parquet\n",
      "    Runtime: (31.37%) 0 seconds [13.10 milliseconds±0.17 milliseconds/batch]\n",
      "    Stats: {input_files: 1, doc_len: 3281041 [min=217, max=209976, 3281.04±8081/doc], doc_len_tokens: 748872 [min=52, max=46263, 748.87±1833/doc], documents: 1000 [1000.00/input_file]}\n",
      "🔻 - FILTER: 👤 Lambda\n",
      "    Runtime: (68.63%) 0 seconds [0.06 milliseconds±0.14 milliseconds/doc]\n",
      "    Stats: {total: 1000, dropped: 1000}\n",
      "💽 - WRITER: 🐿 Jsonl\n",
      "2024-04-22 22:32:37.472 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 6/10 tasks completed.\n",
      "2024-04-22 22:32:38.815 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 7/10 tasks completed.\n",
      "2024-04-22 22:32:39.985 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 8/10 tasks completed.\n",
      "2024-04-22 22:32:44.966 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 9/10 tasks completed.\n",
      "2024-04-22 22:32:46.847 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 10/10 tasks completed.\n",
      "\u001b[32m2024-04-22 22:32:46.943\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m146\u001b[0m - \u001b[32m\u001b[1m\n",
      "\n",
      "📉📉📉 Stats: All 10 tasks 📉📉📉\n",
      "\n",
      "Total Runtime: 0 seconds ± 0 seconds/task\n",
      "\n",
      "📖 - READER: 📒 Parquet\n",
      "    Runtime: (30.61%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [12.87 milliseconds±4.46 milliseconds/batch]\n",
      "    Stats: {input_files: 10, doc_len: 32302611 [min=190, max=561858, 3230.26±8782/doc], doc_len_tokens: 7382072 [min=45, max=118076, 738.21±1915/doc], documents: 10000 [1000.00/input_file]}\n",
      "🔻 - FILTER: 👤 Lambda\n",
      "    Runtime: (69.39%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [0.06 milliseconds±0.14 milliseconds/doc]\n",
      "    Stats: {total: 10000, dropped: 10000}\n",
      "💽 - WRITER: 🐿 Jsonl\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "📉📉📉 Stats 📉📉📉\n",
       "\n",
       "Total Runtime: 0 seconds ± 0 seconds/task\n",
       "\n",
       "📖 - READER: 📒 Parquet\n",
       "    Runtime: (30.61%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [12.87 milliseconds±4.46 milliseconds/batch]\n",
       "    Stats: {input_files: 10, doc_len: 32302611 [min=190, max=561858, 3230.26±8782/doc], doc_len_tokens: 7382072 [min=45, max=118076, 738.21±1915/doc], documents: 10000 [1000.00/input_file]}\n",
       "🔻 - FILTER: 👤 Lambda\n",
       "    Runtime: (69.39%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [0.06 milliseconds±0.14 milliseconds/doc]\n",
       "    Stats: {total: 10000, dropped: 10000}\n",
       "💽 - WRITER: 🐿 Jsonl"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datatrove.pipeline.readers import ParquetReader\n",
    "from datatrove.pipeline.filters import LambdaFilter\n",
    "from datatrove.pipeline.writers import JsonlWriter\n",
    "from datatrove.executor import LocalPipelineExecutor\n",
    "from datatrove.pipeline.writers import JsonlWriter\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='debug.log', level=logging.DEBUG)\n",
    "\n",
    "# Function to check if any of the keywords are present in the document text\n",
    "def is_dentistry_related(document):\n",
    "    dentistry_keywords = [\n",
    "        'osseointegration', 'bone quality and volume assessment', 'anatomical constraints in implant placement',\n",
    "        'digital surgical guides', 'minimally invasive surgical techniques', 'template-guided implant placement',\n",
    "        'immediate implant loading', 'alveolar ridge preservation and augmentation', 'biomaterials for bone regeneration',\n",
    "        'barrier membranes in guided bone regeneration', 'periodontal tissue engineering', 'soft tissue augmentation around implants',\n",
    "        'peri-implantitis incidence and treatment', 'zygomatic and pterygoid implants', 'socket shield technique',\n",
    "        'CAD/CAM in prosthodontics', 'digital impression taking', 'optical intraoral scanning', '3D printing in denture fabrication',\n",
    "        'virtual reality in dental education', 'computer-aided implant surgery', 'teledentistry applications',\n",
    "        'machine learning in diagnostic imaging', 'predictive analytics in treatment planning', 'AI-driven patient management systems',\n",
    "        'automated patient monitoring', 'robotics in dental surgery', 'novel bone grafting materials', 'resorbable vs. non-resorbable membranes',\n",
    "        'cross-linked collagen membranes', 'synthetic resorbable membranes', 'tenting techniques for space maintenance',\n",
    "        'growth factor delivery systems', 'survival rates and failure modes of dental implants', 'comparative studies on flap vs. flapless implant surgery',\n",
    "        'meta-analysis and systematic reviews in implantology', 'clinical trials on new implant designs', 'patient-reported outcomes in implant dentistry'\n",
    "    ]\n",
    "    try:\n",
    "        text = document.text.lower()\n",
    "    except AttributeError as e:\n",
    "        logging.error(f\"Error accessing document text: {e}\")\n",
    "        logging.info(f\"Document type: {type(document)}\")\n",
    "        logging.info(f\"Document attributes/methods: {dir(document)}\")\n",
    "        return False\n",
    "    return any(keyword in text for keyword in dentistry_keywords)\n",
    "\n",
    "# Set the output path to your LaCie external driven and create a folder for the output named \"Dentistry_database\"\n",
    "lacie_path = \"/Volumes/LaCie\"\n",
    "output_folder = \"technical_dental_database\"\n",
    "output_path = os.path.join(lacie_path, output_folder)\n",
    "print(\"Output path:\", output_path)  # Debugging output path\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Set up the data processing pipeline\n",
    "# Define the pipeline\n",
    "pipeline = [\n",
    "    ParquetReader(\"hf://datasets/HuggingFaceFW/fineweb/data\", limit=1000),\n",
    "    LambdaFilter(is_dentistry_related),\n",
    "    JsonlWriter(output_path)\n",
    "]\n",
    "\n",
    "# Create and run the pipeline executor\n",
    "pipeline_executor = LocalPipelineExecutor(pipeline=pipeline, tasks=10)\n",
    "pipeline_executor.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: /Volumes/LaCie/technical_dental_database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 22:37:19.706 | INFO     | datatrove.utils.logging:add_task_logger:47 - Launching pipeline for rank=0\n",
      "2024-04-22 22:37:19.708 | INFO     | datatrove.utils.logging:log_pipeline:76 - \n",
      "--- 🛠️ PIPELINE 🛠\n",
      "📖 - READER: 📒 Parquet\n",
      "🔻 - FILTER: 👤 Lambda\n",
      "💽 - WRITER: 🐿 Jsonl\n",
      "2024-04-22 22:37:34.997 | INFO     | datatrove.pipeline.readers.base:read_files_shard:193 - Reading input file CC-MAIN-2013-20/000_00000.parquet\n",
      "2024-04-22 22:37:37.998 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 1/10 tasks completed.\n",
      "2024-04-22 22:37:38.294 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 2/10 tasks completed.\n",
      "2024-04-22 22:37:40.057 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 3/10 tasks completed.\n",
      "2024-04-22 22:37:43.895 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 4/10 tasks completed.\n",
      "2024-04-22 22:37:43.900 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 5/10 tasks completed.\n",
      "2024-04-22 22:37:44.077 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 6/10 tasks completed.\n",
      "2024-04-22 22:37:45.790 | SUCCESS  | datatrove.executor.base:_run_for_rank:85 - Processing done for rank=0\n",
      "2024-04-22 22:37:45.802 | INFO     | datatrove.executor.base:_run_for_rank:91 - \n",
      "\n",
      "📉📉📉 Stats: Task 0 📉📉📉\n",
      "\n",
      "Total Runtime: 0 seconds\n",
      "\n",
      "📖 - READER: 📒 Parquet\n",
      "    Runtime: (29.23%) 0 seconds [18.12 milliseconds±4.06 milliseconds/batch]\n",
      "    Stats: {input_files: 1, doc_len: 3281041 [min=217, max=209976, 3281.04±8081/doc], doc_len_tokens: 748872 [min=52, max=46263, 748.87±1833/doc], documents: 1000 [1000.00/input_file]}\n",
      "🔻 - FILTER: 👤 Lambda\n",
      "    Runtime: (46.60%) 0 seconds [0.06 milliseconds±0.08 milliseconds/doc]\n",
      "    Stats: {total: 1000, dropped: 983, forwarded: 17, doc_len: 427316 [min=1032, max=209976, 25136.24±50981/doc], doc_len_tokens: 95295 [min=219, max=46263, 5605.59±11203/doc]}\n",
      "💽 - WRITER: 🐿 Jsonl\n",
      "    Runtime: (24.18%) 0 seconds [1.76 milliseconds±3.04 milliseconds/doc]\n",
      "    Stats: {XXXXX.jsonl.gz: 17, total: 17, doc_len: 427316 [min=1032, max=209976, 25136.24±50981/doc], doc_len_tokens: 95295 [min=219, max=46263, 5605.59±11203/doc]}\n",
      "2024-04-22 22:37:45.818 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 7/10 tasks completed.\n",
      "2024-04-22 22:37:48.699 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 8/10 tasks completed.\n",
      "2024-04-22 22:37:49.705 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 9/10 tasks completed.\n",
      "2024-04-22 22:37:50.164 | INFO     | datatrove.executor.local:_launch_run_for_rank:79 - 10/10 tasks completed.\n",
      "\u001b[32m2024-04-22 22:37:50.273\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m146\u001b[0m - \u001b[32m\u001b[1m\n",
      "\n",
      "📉📉📉 Stats: All 10 tasks 📉📉📉\n",
      "\n",
      "Total Runtime: 0 seconds ± 0 seconds/task\n",
      "\n",
      "📖 - READER: 📒 Parquet\n",
      "    Runtime: (33.02%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [23.44 milliseconds±17.37 milliseconds/batch]\n",
      "    Stats: {input_files: 10, doc_len: 32302611 [min=190, max=561858, 3230.26±8782/doc], doc_len_tokens: 7382072 [min=45, max=118076, 738.21±1915/doc], documents: 10000 [1000.00/input_file]}\n",
      "🔻 - FILTER: 👤 Lambda\n",
      "    Runtime: (47.96%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [0.07 milliseconds±0.17 milliseconds/doc]\n",
      "    Stats: {total: 10000, dropped: 9843, forwarded: 157, doc_len: 3224016 [min=456, max=561858, 20535.13±56915/doc], doc_len_tokens: 714652 [min=110, max=118076, 4551.92±12047/doc]}\n",
      "💽 - WRITER: 🐿 Jsonl\n",
      "    Runtime: (19.02%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [1.72 milliseconds±4.25 milliseconds/doc]\n",
      "    Stats: {XXXXX.jsonl.gz: 157, total: 157, doc_len: 3224016 [min=456, max=561858, 20535.13±56915/doc], doc_len_tokens: 714652 [min=110, max=118076, 4551.92±12047/doc]}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "📉📉📉 Stats 📉📉📉\n",
       "\n",
       "Total Runtime: 0 seconds ± 0 seconds/task\n",
       "\n",
       "📖 - READER: 📒 Parquet\n",
       "    Runtime: (33.02%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [23.44 milliseconds±17.37 milliseconds/batch]\n",
       "    Stats: {input_files: 10, doc_len: 32302611 [min=190, max=561858, 3230.26±8782/doc], doc_len_tokens: 7382072 [min=45, max=118076, 738.21±1915/doc], documents: 10000 [1000.00/input_file]}\n",
       "🔻 - FILTER: 👤 Lambda\n",
       "    Runtime: (47.96%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [0.07 milliseconds±0.17 milliseconds/doc]\n",
       "    Stats: {total: 10000, dropped: 9843, forwarded: 157, doc_len: 3224016 [min=456, max=561858, 20535.13±56915/doc], doc_len_tokens: 714652 [min=110, max=118076, 4551.92±12047/doc]}\n",
       "💽 - WRITER: 🐿 Jsonl\n",
       "    Runtime: (19.02%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [1.72 milliseconds±4.25 milliseconds/doc]\n",
       "    Stats: {XXXXX.jsonl.gz: 157, total: 157, doc_len: 3224016 [min=456, max=561858, 20535.13±56915/doc], doc_len_tokens: 714652 [min=110, max=118076, 4551.92±12047/doc]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datatrove.pipeline.readers import ParquetReader\n",
    "from datatrove.pipeline.filters import LambdaFilter\n",
    "from datatrove.pipeline.writers import JsonlWriter\n",
    "from datatrove.executor import LocalPipelineExecutor\n",
    "from datatrove.pipeline.writers import JsonlWriter\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='debug.log', level=logging.DEBUG)\n",
    "\n",
    "# Function to check if any of the keywords are present in the document text\n",
    "def is_dentistry_related(document):\n",
    "    dentistry_keywords = [\n",
    "        'dentistry', 'dental', 'dentist','osseointegration', 'bone quality and volume assessment', 'anatomical constraints in implant placement',\n",
    "        'digital surgical guides', 'minimally invasive surgical techniques', 'template-guided implant placement',\n",
    "        'immediate implant loading', 'alveolar ridge preservation and augmentation', 'biomaterials for bone regeneration',\n",
    "        'barrier membranes in guided bone regeneration', 'periodontal tissue engineering', 'soft tissue augmentation around implants',\n",
    "        'peri-implantitis incidence and treatment', 'zygomatic and pterygoid implants', 'socket shield technique',\n",
    "        'CAD/CAM in prosthodontics', 'digital impression taking', 'optical intraoral scanning', '3D printing in denture fabrication',\n",
    "        'virtual reality in dental education', 'computer-aided implant surgery', 'teledentistry applications',\n",
    "        'machine learning in diagnostic imaging', 'predictive analytics in treatment planning', 'AI-driven patient management systems',\n",
    "        'automated patient monitoring', 'robotics in dental surgery', 'novel bone grafting materials', 'resorbable vs. non-resorbable membranes',\n",
    "        'cross-linked collagen membranes', 'synthetic resorbable membranes', 'tenting techniques for space maintenance',\n",
    "        'growth factor delivery systems', 'survival rates and failure modes of dental implants', 'comparative studies on flap vs. flapless implant surgery',\n",
    "        'meta-analysis and systematic reviews in implantology', 'clinical trials on new implant designs', 'patient-reported outcomes in implant dentistry'\n",
    "    ]\n",
    "    try:\n",
    "        text = document.text.lower()\n",
    "    except AttributeError as e:\n",
    "        logging.error(f\"Error accessing document text: {e}\")\n",
    "        logging.info(f\"Document type: {type(document)}\")\n",
    "        logging.info(f\"Document attributes/methods: {dir(document)}\")\n",
    "        return False\n",
    "    return any(keyword in text for keyword in dentistry_keywords)\n",
    "\n",
    "# Set the output path to your LaCie external driven and create a folder for the output named \"Dentistry_database\"\n",
    "lacie_path = \"/Volumes/LaCie\"\n",
    "output_folder = \"technical_dental_database\"\n",
    "output_path = os.path.join(lacie_path, output_folder)\n",
    "print(\"Output path:\", output_path)  # Debugging output path\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Set up the data processing pipeline\n",
    "# Define the pipeline\n",
    "pipeline = [\n",
    "    ParquetReader(\"hf://datasets/HuggingFaceFW/fineweb/data\", limit=1000),\n",
    "    LambdaFilter(is_dentistry_related),\n",
    "    JsonlWriter(output_path)\n",
    "]\n",
    "\n",
    "# Create and run the pipeline executor\n",
    "pipeline_executor = LocalPipelineExecutor(pipeline=pipeline, tasks=10)\n",
    "pipeline_executor.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlitapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
